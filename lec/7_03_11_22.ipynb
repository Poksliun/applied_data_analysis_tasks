{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "df = pd.read_csv('dir_for_csv_file/Онкология.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "data": {
      "text/plain": "     842302  M  17.99  10.38   122.8    1001   0.1184   0.2776  0.3001  \\\n0    842517  M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869   \n1  84300903  M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974   \n2  84348301  M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414   \n3  84358402  M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980   \n4    843786  M  12.45  15.70   82.57   477.1  0.12780  0.17000  0.1578   \n\n    0.1471  ...  25.38  17.33   184.6    2019  0.1622  0.6656  0.7119  0.2654  \\\n0  0.07017  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n1  0.12790  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n2  0.10520  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n3  0.10430  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n4  0.08089  ...  15.47  23.75  103.40   741.6  0.1791  0.5249  0.5355  0.1741   \n\n   0.4601   0.1189  \n0  0.2750  0.08902  \n1  0.3613  0.08758  \n2  0.6638  0.17300  \n3  0.2364  0.07678  \n4  0.3985  0.12440  \n\n[5 rows x 32 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>842302</th>\n      <th>M</th>\n      <th>17.99</th>\n      <th>10.38</th>\n      <th>122.8</th>\n      <th>1001</th>\n      <th>0.1184</th>\n      <th>0.2776</th>\n      <th>0.3001</th>\n      <th>0.1471</th>\n      <th>...</th>\n      <th>25.38</th>\n      <th>17.33</th>\n      <th>184.6</th>\n      <th>2019</th>\n      <th>0.1622</th>\n      <th>0.6656</th>\n      <th>0.7119</th>\n      <th>0.2654</th>\n      <th>0.4601</th>\n      <th>0.1189</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>842517</td>\n      <td>M</td>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.0869</td>\n      <td>0.07017</td>\n      <td>...</td>\n      <td>24.99</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>84300903</td>\n      <td>M</td>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.1974</td>\n      <td>0.12790</td>\n      <td>...</td>\n      <td>23.57</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>84348301</td>\n      <td>M</td>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.2414</td>\n      <td>0.10520</td>\n      <td>...</td>\n      <td>14.91</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.2098</td>\n      <td>0.8663</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>84358402</td>\n      <td>M</td>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.1980</td>\n      <td>0.10430</td>\n      <td>...</td>\n      <td>22.54</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.1374</td>\n      <td>0.2050</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>843786</td>\n      <td>M</td>\n      <td>12.45</td>\n      <td>15.70</td>\n      <td>82.57</td>\n      <td>477.1</td>\n      <td>0.12780</td>\n      <td>0.17000</td>\n      <td>0.1578</td>\n      <td>0.08089</td>\n      <td>...</td>\n      <td>15.47</td>\n      <td>23.75</td>\n      <td>103.40</td>\n      <td>741.6</td>\n      <td>0.1791</td>\n      <td>0.5249</td>\n      <td>0.5355</td>\n      <td>0.1741</td>\n      <td>0.3985</td>\n      <td>0.12440</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 32 columns</p>\n</div>"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() #Посмотрим на наши данные, видно, что заголовки столбцов отсутствуют."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 568 entries, 0 to 567\n",
      "Data columns (total 32 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   842302    568 non-null    int64  \n",
      " 1   M         568 non-null    object \n",
      " 2   17.99     568 non-null    float64\n",
      " 3   10.38     568 non-null    float64\n",
      " 4   122.8     568 non-null    float64\n",
      " 5   1001      568 non-null    float64\n",
      " 6   0.1184    568 non-null    float64\n",
      " 7   0.2776    568 non-null    float64\n",
      " 8   0.3001    568 non-null    float64\n",
      " 9   0.1471    568 non-null    float64\n",
      " 10  0.2419    568 non-null    float64\n",
      " 11  0.07871   568 non-null    float64\n",
      " 12  1.095     568 non-null    float64\n",
      " 13  0.9053    568 non-null    float64\n",
      " 14  8.589     568 non-null    float64\n",
      " 15  153.4     568 non-null    float64\n",
      " 16  0.006399  568 non-null    float64\n",
      " 17  0.04904   568 non-null    float64\n",
      " 18  0.05373   568 non-null    float64\n",
      " 19  0.01587   568 non-null    float64\n",
      " 20  0.03003   568 non-null    float64\n",
      " 21  0.006193  568 non-null    float64\n",
      " 22  25.38     568 non-null    float64\n",
      " 23  17.33     568 non-null    float64\n",
      " 24  184.6     568 non-null    float64\n",
      " 25  2019      568 non-null    float64\n",
      " 26  0.1622    568 non-null    float64\n",
      " 27  0.6656    568 non-null    float64\n",
      " 28  0.7119    568 non-null    float64\n",
      " 29  0.2654    568 non-null    float64\n",
      " 30  0.4601    568 non-null    float64\n",
      " 31  0.1189    568 non-null    float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info() #посмотрим на сводную информацию"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "df.columns = [\"id\", \"diagnosis\", \"radius_mean\", \"texture_mean\", \"perimeter_mean\", \"area_mean\",\n",
    "                                      \"smoothness_mean\", \"compactness_mean\", \"concavity_mean\", \"concave points_mean\",\n",
    "                                      \"symmetry_mean\", \"fractal_dimension_mean\", \"radius_se\", \"texture_se\",\n",
    "                                      \"perimeter_se\", \"area_se\", \"smoothness_se\", \"compactness_se\", \"concavity_se\",\n",
    "                                      \"concave points_se\", \"symmetry_se\", \"fractal_dimension_se\", \"radius_worst\",\n",
    "                                      \"texture_worst\", \"perimeter_worst\", \"area_worst\", \"smoothness_worst\",\n",
    "                                      \"compactness_worst\", \"concavity_worst\", \"concave points_worst\", \"symmetry_worst\",\n",
    "                                      \"fractal_dimension_worst\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "data": {
      "text/plain": "          id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n0     842517         M        20.57         17.77          132.90     1326.0   \n1   84300903         M        19.69         21.25          130.00     1203.0   \n2   84348301         M        11.42         20.38           77.58      386.1   \n3   84358402         M        20.29         14.34          135.10     1297.0   \n4     843786         M        12.45         15.70           82.57      477.1   \n5     844359         M        18.25         19.98          119.60     1040.0   \n6   84458202         M        13.71         20.83           90.20      577.9   \n7     844981         M        13.00         21.82           87.50      519.8   \n8   84501001         M        12.46         24.04           83.97      475.9   \n9     845636         M        16.02         23.24          102.70      797.8   \n10  84610002         M        15.78         17.89          103.60      781.0   \n11    846226         M        19.17         24.80          132.40     1123.0   \n12    846381         M        15.85         23.95          103.70      782.7   \n13  84667401         M        13.73         22.61           93.60      578.3   \n14  84799002         M        14.54         27.54           96.73      658.8   \n15    848406         M        14.68         20.13           94.74      684.5   \n16  84862001         M        16.13         20.68          108.10      798.8   \n17    849014         M        19.81         22.15          130.00     1260.0   \n18   8510426         B        13.54         14.36           87.46      566.3   \n19   8510653         B        13.08         15.71           85.63      520.0   \n\n    smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n0           0.08474           0.07864         0.08690              0.07017   \n1           0.10960           0.15990         0.19740              0.12790   \n2           0.14250           0.28390         0.24140              0.10520   \n3           0.10030           0.13280         0.19800              0.10430   \n4           0.12780           0.17000         0.15780              0.08089   \n5           0.09463           0.10900         0.11270              0.07400   \n6           0.11890           0.16450         0.09366              0.05985   \n7           0.12730           0.19320         0.18590              0.09353   \n8           0.11860           0.23960         0.22730              0.08543   \n9           0.08206           0.06669         0.03299              0.03323   \n10          0.09710           0.12920         0.09954              0.06606   \n11          0.09740           0.24580         0.20650              0.11180   \n12          0.08401           0.10020         0.09938              0.05364   \n13          0.11310           0.22930         0.21280              0.08025   \n14          0.11390           0.15950         0.16390              0.07364   \n15          0.09867           0.07200         0.07395              0.05259   \n16          0.11700           0.20220         0.17220              0.10280   \n17          0.09831           0.10270         0.14790              0.09498   \n18          0.09779           0.08129         0.06664              0.04781   \n19          0.10750           0.12700         0.04568              0.03110   \n\n    ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n0   ...         24.99          23.41           158.80      1956.0   \n1   ...         23.57          25.53           152.50      1709.0   \n2   ...         14.91          26.50            98.87       567.7   \n3   ...         22.54          16.67           152.20      1575.0   \n4   ...         15.47          23.75           103.40       741.6   \n5   ...         22.88          27.66           153.20      1606.0   \n6   ...         17.06          28.14           110.60       897.0   \n7   ...         15.49          30.73           106.20       739.3   \n8   ...         15.09          40.68            97.65       711.4   \n9   ...         19.19          33.88           123.80      1150.0   \n10  ...         20.42          27.28           136.50      1299.0   \n11  ...         20.96          29.94           151.70      1332.0   \n12  ...         16.84          27.66           112.00       876.5   \n13  ...         15.03          32.01           108.80       697.7   \n14  ...         17.46          37.13           124.10       943.2   \n15  ...         19.07          30.88           123.40      1138.0   \n16  ...         20.96          31.48           136.80      1315.0   \n17  ...         27.32          30.88           186.80      2398.0   \n18  ...         15.11          19.26            99.70       711.2   \n19  ...         14.50          20.49            96.09       630.5   \n\n    smoothness_worst  compactness_worst  concavity_worst  \\\n0             0.1238             0.1866           0.2416   \n1             0.1444             0.4245           0.4504   \n2             0.2098             0.8663           0.6869   \n3             0.1374             0.2050           0.4000   \n4             0.1791             0.5249           0.5355   \n5             0.1442             0.2576           0.3784   \n6             0.1654             0.3682           0.2678   \n7             0.1703             0.5401           0.5390   \n8             0.1853             1.0580           1.1050   \n9             0.1181             0.1551           0.1459   \n10            0.1396             0.5609           0.3965   \n11            0.1037             0.3903           0.3639   \n12            0.1131             0.1924           0.2322   \n13            0.1651             0.7725           0.6943   \n14            0.1678             0.6577           0.7026   \n15            0.1464             0.1871           0.2914   \n16            0.1789             0.4233           0.4784   \n17            0.1512             0.3150           0.5372   \n18            0.1440             0.1773           0.2390   \n19            0.1312             0.2776           0.1890   \n\n    concave points_worst  symmetry_worst  fractal_dimension_worst  \n0                0.18600          0.2750                  0.08902  \n1                0.24300          0.3613                  0.08758  \n2                0.25750          0.6638                  0.17300  \n3                0.16250          0.2364                  0.07678  \n4                0.17410          0.3985                  0.12440  \n5                0.19320          0.3063                  0.08368  \n6                0.15560          0.3196                  0.11510  \n7                0.20600          0.4378                  0.10720  \n8                0.22100          0.4366                  0.20750  \n9                0.09975          0.2948                  0.08452  \n10               0.18100          0.3792                  0.10480  \n11               0.17670          0.3176                  0.10230  \n12               0.11190          0.2809                  0.06287  \n13               0.22080          0.3596                  0.14310  \n14               0.17120          0.4218                  0.13410  \n15               0.16090          0.3029                  0.08216  \n16               0.20730          0.3706                  0.11420  \n17               0.23880          0.2768                  0.07615  \n18               0.12880          0.2977                  0.07259  \n19               0.07283          0.3184                  0.08183  \n\n[20 rows x 32 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>diagnosis</th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>...</th>\n      <th>radius_worst</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>842517</td>\n      <td>M</td>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.08690</td>\n      <td>0.07017</td>\n      <td>...</td>\n      <td>24.99</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.18600</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>84300903</td>\n      <td>M</td>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.19740</td>\n      <td>0.12790</td>\n      <td>...</td>\n      <td>23.57</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.24300</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>84348301</td>\n      <td>M</td>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.24140</td>\n      <td>0.10520</td>\n      <td>...</td>\n      <td>14.91</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.2098</td>\n      <td>0.8663</td>\n      <td>0.6869</td>\n      <td>0.25750</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>84358402</td>\n      <td>M</td>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.19800</td>\n      <td>0.10430</td>\n      <td>...</td>\n      <td>22.54</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.1374</td>\n      <td>0.2050</td>\n      <td>0.4000</td>\n      <td>0.16250</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>843786</td>\n      <td>M</td>\n      <td>12.45</td>\n      <td>15.70</td>\n      <td>82.57</td>\n      <td>477.1</td>\n      <td>0.12780</td>\n      <td>0.17000</td>\n      <td>0.15780</td>\n      <td>0.08089</td>\n      <td>...</td>\n      <td>15.47</td>\n      <td>23.75</td>\n      <td>103.40</td>\n      <td>741.6</td>\n      <td>0.1791</td>\n      <td>0.5249</td>\n      <td>0.5355</td>\n      <td>0.17410</td>\n      <td>0.3985</td>\n      <td>0.12440</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>844359</td>\n      <td>M</td>\n      <td>18.25</td>\n      <td>19.98</td>\n      <td>119.60</td>\n      <td>1040.0</td>\n      <td>0.09463</td>\n      <td>0.10900</td>\n      <td>0.11270</td>\n      <td>0.07400</td>\n      <td>...</td>\n      <td>22.88</td>\n      <td>27.66</td>\n      <td>153.20</td>\n      <td>1606.0</td>\n      <td>0.1442</td>\n      <td>0.2576</td>\n      <td>0.3784</td>\n      <td>0.19320</td>\n      <td>0.3063</td>\n      <td>0.08368</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>84458202</td>\n      <td>M</td>\n      <td>13.71</td>\n      <td>20.83</td>\n      <td>90.20</td>\n      <td>577.9</td>\n      <td>0.11890</td>\n      <td>0.16450</td>\n      <td>0.09366</td>\n      <td>0.05985</td>\n      <td>...</td>\n      <td>17.06</td>\n      <td>28.14</td>\n      <td>110.60</td>\n      <td>897.0</td>\n      <td>0.1654</td>\n      <td>0.3682</td>\n      <td>0.2678</td>\n      <td>0.15560</td>\n      <td>0.3196</td>\n      <td>0.11510</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>844981</td>\n      <td>M</td>\n      <td>13.00</td>\n      <td>21.82</td>\n      <td>87.50</td>\n      <td>519.8</td>\n      <td>0.12730</td>\n      <td>0.19320</td>\n      <td>0.18590</td>\n      <td>0.09353</td>\n      <td>...</td>\n      <td>15.49</td>\n      <td>30.73</td>\n      <td>106.20</td>\n      <td>739.3</td>\n      <td>0.1703</td>\n      <td>0.5401</td>\n      <td>0.5390</td>\n      <td>0.20600</td>\n      <td>0.4378</td>\n      <td>0.10720</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>84501001</td>\n      <td>M</td>\n      <td>12.46</td>\n      <td>24.04</td>\n      <td>83.97</td>\n      <td>475.9</td>\n      <td>0.11860</td>\n      <td>0.23960</td>\n      <td>0.22730</td>\n      <td>0.08543</td>\n      <td>...</td>\n      <td>15.09</td>\n      <td>40.68</td>\n      <td>97.65</td>\n      <td>711.4</td>\n      <td>0.1853</td>\n      <td>1.0580</td>\n      <td>1.1050</td>\n      <td>0.22100</td>\n      <td>0.4366</td>\n      <td>0.20750</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>845636</td>\n      <td>M</td>\n      <td>16.02</td>\n      <td>23.24</td>\n      <td>102.70</td>\n      <td>797.8</td>\n      <td>0.08206</td>\n      <td>0.06669</td>\n      <td>0.03299</td>\n      <td>0.03323</td>\n      <td>...</td>\n      <td>19.19</td>\n      <td>33.88</td>\n      <td>123.80</td>\n      <td>1150.0</td>\n      <td>0.1181</td>\n      <td>0.1551</td>\n      <td>0.1459</td>\n      <td>0.09975</td>\n      <td>0.2948</td>\n      <td>0.08452</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>84610002</td>\n      <td>M</td>\n      <td>15.78</td>\n      <td>17.89</td>\n      <td>103.60</td>\n      <td>781.0</td>\n      <td>0.09710</td>\n      <td>0.12920</td>\n      <td>0.09954</td>\n      <td>0.06606</td>\n      <td>...</td>\n      <td>20.42</td>\n      <td>27.28</td>\n      <td>136.50</td>\n      <td>1299.0</td>\n      <td>0.1396</td>\n      <td>0.5609</td>\n      <td>0.3965</td>\n      <td>0.18100</td>\n      <td>0.3792</td>\n      <td>0.10480</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>846226</td>\n      <td>M</td>\n      <td>19.17</td>\n      <td>24.80</td>\n      <td>132.40</td>\n      <td>1123.0</td>\n      <td>0.09740</td>\n      <td>0.24580</td>\n      <td>0.20650</td>\n      <td>0.11180</td>\n      <td>...</td>\n      <td>20.96</td>\n      <td>29.94</td>\n      <td>151.70</td>\n      <td>1332.0</td>\n      <td>0.1037</td>\n      <td>0.3903</td>\n      <td>0.3639</td>\n      <td>0.17670</td>\n      <td>0.3176</td>\n      <td>0.10230</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>846381</td>\n      <td>M</td>\n      <td>15.85</td>\n      <td>23.95</td>\n      <td>103.70</td>\n      <td>782.7</td>\n      <td>0.08401</td>\n      <td>0.10020</td>\n      <td>0.09938</td>\n      <td>0.05364</td>\n      <td>...</td>\n      <td>16.84</td>\n      <td>27.66</td>\n      <td>112.00</td>\n      <td>876.5</td>\n      <td>0.1131</td>\n      <td>0.1924</td>\n      <td>0.2322</td>\n      <td>0.11190</td>\n      <td>0.2809</td>\n      <td>0.06287</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>84667401</td>\n      <td>M</td>\n      <td>13.73</td>\n      <td>22.61</td>\n      <td>93.60</td>\n      <td>578.3</td>\n      <td>0.11310</td>\n      <td>0.22930</td>\n      <td>0.21280</td>\n      <td>0.08025</td>\n      <td>...</td>\n      <td>15.03</td>\n      <td>32.01</td>\n      <td>108.80</td>\n      <td>697.7</td>\n      <td>0.1651</td>\n      <td>0.7725</td>\n      <td>0.6943</td>\n      <td>0.22080</td>\n      <td>0.3596</td>\n      <td>0.14310</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>84799002</td>\n      <td>M</td>\n      <td>14.54</td>\n      <td>27.54</td>\n      <td>96.73</td>\n      <td>658.8</td>\n      <td>0.11390</td>\n      <td>0.15950</td>\n      <td>0.16390</td>\n      <td>0.07364</td>\n      <td>...</td>\n      <td>17.46</td>\n      <td>37.13</td>\n      <td>124.10</td>\n      <td>943.2</td>\n      <td>0.1678</td>\n      <td>0.6577</td>\n      <td>0.7026</td>\n      <td>0.17120</td>\n      <td>0.4218</td>\n      <td>0.13410</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>848406</td>\n      <td>M</td>\n      <td>14.68</td>\n      <td>20.13</td>\n      <td>94.74</td>\n      <td>684.5</td>\n      <td>0.09867</td>\n      <td>0.07200</td>\n      <td>0.07395</td>\n      <td>0.05259</td>\n      <td>...</td>\n      <td>19.07</td>\n      <td>30.88</td>\n      <td>123.40</td>\n      <td>1138.0</td>\n      <td>0.1464</td>\n      <td>0.1871</td>\n      <td>0.2914</td>\n      <td>0.16090</td>\n      <td>0.3029</td>\n      <td>0.08216</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>84862001</td>\n      <td>M</td>\n      <td>16.13</td>\n      <td>20.68</td>\n      <td>108.10</td>\n      <td>798.8</td>\n      <td>0.11700</td>\n      <td>0.20220</td>\n      <td>0.17220</td>\n      <td>0.10280</td>\n      <td>...</td>\n      <td>20.96</td>\n      <td>31.48</td>\n      <td>136.80</td>\n      <td>1315.0</td>\n      <td>0.1789</td>\n      <td>0.4233</td>\n      <td>0.4784</td>\n      <td>0.20730</td>\n      <td>0.3706</td>\n      <td>0.11420</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>849014</td>\n      <td>M</td>\n      <td>19.81</td>\n      <td>22.15</td>\n      <td>130.00</td>\n      <td>1260.0</td>\n      <td>0.09831</td>\n      <td>0.10270</td>\n      <td>0.14790</td>\n      <td>0.09498</td>\n      <td>...</td>\n      <td>27.32</td>\n      <td>30.88</td>\n      <td>186.80</td>\n      <td>2398.0</td>\n      <td>0.1512</td>\n      <td>0.3150</td>\n      <td>0.5372</td>\n      <td>0.23880</td>\n      <td>0.2768</td>\n      <td>0.07615</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>8510426</td>\n      <td>B</td>\n      <td>13.54</td>\n      <td>14.36</td>\n      <td>87.46</td>\n      <td>566.3</td>\n      <td>0.09779</td>\n      <td>0.08129</td>\n      <td>0.06664</td>\n      <td>0.04781</td>\n      <td>...</td>\n      <td>15.11</td>\n      <td>19.26</td>\n      <td>99.70</td>\n      <td>711.2</td>\n      <td>0.1440</td>\n      <td>0.1773</td>\n      <td>0.2390</td>\n      <td>0.12880</td>\n      <td>0.2977</td>\n      <td>0.07259</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>8510653</td>\n      <td>B</td>\n      <td>13.08</td>\n      <td>15.71</td>\n      <td>85.63</td>\n      <td>520.0</td>\n      <td>0.10750</td>\n      <td>0.12700</td>\n      <td>0.04568</td>\n      <td>0.03110</td>\n      <td>...</td>\n      <td>14.50</td>\n      <td>20.49</td>\n      <td>96.09</td>\n      <td>630.5</td>\n      <td>0.1312</td>\n      <td>0.2776</td>\n      <td>0.1890</td>\n      <td>0.07283</td>\n      <td>0.3184</td>\n      <td>0.08183</td>\n    </tr>\n  </tbody>\n</table>\n<p>20 rows × 32 columns</p>\n</div>"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20) #Посмотрим на наши данные еще раз, видно, что заголовки появились."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 568 entries, 0 to 567\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       568 non-null    int64  \n",
      " 1   diagnosis                568 non-null    object \n",
      " 2   radius_mean              568 non-null    float64\n",
      " 3   texture_mean             568 non-null    float64\n",
      " 4   perimeter_mean           568 non-null    float64\n",
      " 5   area_mean                568 non-null    float64\n",
      " 6   smoothness_mean          568 non-null    float64\n",
      " 7   compactness_mean         568 non-null    float64\n",
      " 8   concavity_mean           568 non-null    float64\n",
      " 9   concave points_mean      568 non-null    float64\n",
      " 10  symmetry_mean            568 non-null    float64\n",
      " 11  fractal_dimension_mean   568 non-null    float64\n",
      " 12  radius_se                568 non-null    float64\n",
      " 13  texture_se               568 non-null    float64\n",
      " 14  perimeter_se             568 non-null    float64\n",
      " 15  area_se                  568 non-null    float64\n",
      " 16  smoothness_se            568 non-null    float64\n",
      " 17  compactness_se           568 non-null    float64\n",
      " 18  concavity_se             568 non-null    float64\n",
      " 19  concave points_se        568 non-null    float64\n",
      " 20  symmetry_se              568 non-null    float64\n",
      " 21  fractal_dimension_se     568 non-null    float64\n",
      " 22  radius_worst             568 non-null    float64\n",
      " 23  texture_worst            568 non-null    float64\n",
      " 24  perimeter_worst          568 non-null    float64\n",
      " 25  area_worst               568 non-null    float64\n",
      " 26  smoothness_worst         568 non-null    float64\n",
      " 27  compactness_worst        568 non-null    float64\n",
      " 28  concavity_worst          568 non-null    float64\n",
      " 29  concave points_worst     568 non-null    float64\n",
      " 30  symmetry_worst           568 non-null    float64\n",
      " 31  fractal_dimension_worst  568 non-null    float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info() #посмотрим на сводную информацию еще раз"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "def load_data(data_path): #задаем функцию\n",
    "     ds = pd.read_csv(data_path, names=[\"id\", \"diagnosis\", \"radius_mean\", \"texture_mean\", \"perimeter_mean\", \"area_mean\",\n",
    "                                      \"smoothness_mean\", \"compactness_mean\", \"concavity_mean\", \"concave points_mean\",\n",
    "                                      \"symmetry_mean\", \"fractal_dimension_mean\", \"radius_se\", \"texture_se\",\n",
    "                                      \"perimeter_se\", \"area_se\", \"smoothness_se\", \"compactness_se\", \"concavity_se\",\n",
    "                                      \"concave points_se\", \"symmetry_se\", \"fractal_dimension_se\", \"radius_worst\",\n",
    "                                      \"texture_worst\", \"perimeter_worst\", \"area_worst\", \"smoothness_worst\",\n",
    "                                      \"compactness_worst\", \"concavity_worst\", \"concave points_worst\", \"symmetry_worst\",\n",
    "                                      \"fractal_dimension_worst\"]) #прописываем названия столбцов\n",
    "     y = ds['diagnosis'] #выделяем целевую переменную из общего объема данных\n",
    "     X = ds.drop('diagnosis', axis=1) #удаляем целевую переменную из обучающего множества\n",
    "     X = X.drop('id', axis=1) #удаляем не информативный столбец 'id'\n",
    "     i = len(X.columns)\n",
    "     X = X.drop(X.columns[i - 1], axis=1) #удаляем не информативный столбец 'fractal_dimension_worst'\n",
    "     y.replace(('M', 'B'), (1, 0), inplace=True) #делаем замену значений в целевой переменной на 0 и 1\n",
    "     sc = StandardScaler() #выполняем нормализацию данных, после чего наши данные преобразуются\n",
    "                           #из структуры датафрейм в обычный массив\n",
    "     sc.fit(X)\n",
    "     X_ans = sc.transform(X)\n",
    "     return X_ans, y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [],
   "source": [
    "X, y = load_data(\"dir_for_csv_file/Онкология.csv\") #Применяем написанную функцию для обработки данных из файла\n",
    "# У нас сразу получаются два множества"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 1.09706398, -2.07333501,  1.26993369, ...,  2.10952635,\n         2.29607613,  2.75062224],\n       [ 1.82982061, -0.35363241,  1.68595471, ..., -0.14674897,\n         1.0870843 , -0.24388967],\n       [ 1.57988811,  0.45618695,  1.56650313, ...,  0.85497394,\n         1.95500035,  1.152255  ],\n       ...,\n       [ 0.70228425,  2.0455738 ,  0.67267578, ...,  0.3267666 ,\n         0.41406869, -1.10454895],\n       [ 1.83834103,  2.33645719,  1.98252415, ...,  3.19760468,\n         2.28998549,  1.91908301],\n       [-1.80840125,  1.22179204, -1.81438851, ..., -1.30583065,\n        -1.74506282, -0.04813821]])"
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X #Посмотрим как выглядит теперь множество Х, данные после нормализации не похожи на исходные значения"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# импортируем функцию, которая поможет нам разбить наши данные на обучающую и тестовую выборки."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=777, stratify=y)\n",
    "# Получили четыре множества: два для обучения, другие два - для тестирования."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "from sklearn import svm #импортируем нашу модель"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "best_model = svm.SVC(kernel='linear', C=1, gamma=1) #зададим начальные параметры для модели"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "data": {
      "text/plain": "SVC(C=1, gamma=1, kernel='linear')",
      "text/html": "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, gamma=1, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, gamma=1, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train , y_train) #выполним обучение модели при начальных параметрах"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV # В этот раз тоже используем полный перебор параметров"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "model_params = best_model.get_params() #зададим параметры по которым и будем осуществлять поиск\n",
    "tuned_params = {}\n",
    "for k, v in model_params.items():\n",
    "    tuned_params[k] = [v]\n",
    "tuned_params['gamma'] = range(1, 100)\n",
    "clf = GridSearchCV(best_model, tuned_params, cv=10, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "best_params = clf.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "from sklearn import metrics              # импортируем метрики\n",
    "best_model = svm.SVC(**best_params)      # задаем найденные наилучшие параметры\n",
    "best_model.fit(X_train, y_train)         # обучаем модель\n",
    "predicted = best_model.predict(X_test)   # делаем предсказание"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used params: {'C': 1, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 1, 'kernel': 'linear', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "Evaluation:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        72\n",
      "           1       0.95      0.95      0.95        42\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.96      0.96       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Used params:', best_params)       # выведем наилучшие параметры\n",
    "print('Evaluation:\\n', metrics.classification_report(y_test, predicted))\n",
    "#лучшие значения метрик (те значения, которые получаются при наилучших параметрах модели)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params:\n",
      " {'C': 6, 'kernel': 'rbf'}\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99        72\n",
      "           1       0.98      0.98      0.98        42\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.98      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=svm.SVC()\n",
    "\n",
    "params = {'C': [6,7,8,9,10,11,12],\n",
    "          'kernel': ['linear','rbf']}\n",
    "\n",
    "model_svm = GridSearchCV(model, param_grid=params, n_jobs=-1)\n",
    "model_svm.fit(X_train,y_train)\n",
    "\n",
    "print(\"Best Params:\\n\",model_svm.best_params_)\n",
    "\n",
    "prediction=model_svm.predict(X_test)\n",
    "\n",
    "print(\"Report:\\n\",metrics.classification_report(prediction,y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/Documents/applied_data_analysis_tasks/venv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(model_svm.fit(X_train, y_train), X_test, y_test)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "data": {
      "text/plain": "'1.1.3'"
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}